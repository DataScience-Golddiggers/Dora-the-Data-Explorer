{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "366e04f9",
   "metadata": {},
   "source": [
    "## 6. Riepilogo e Conclusioni\n",
    "\n",
    "La matrice di correlazione mostra:\n",
    "\n",
    "- **Correlazione tra `XGBoost_Proba` e `MLP_Proba`**: Il valore di correlazione tra le probabilità dei due modelli è il dato più importante.\n",
    "  - Un valore **alto (es. > 0.85)** indica che i modelli tendono a fare previsioni molto simili. Concordano sulla maggior parte dei casi.\n",
    "  - Un valore **moderato (es. 0.6 - 0.85)** suggerisce che, pur avendo una tendenza simile, ci sono aree di disaccordo significative. Questo è lo scenario ideale per un *ensemble*, poiché un modello potrebbe correggere gli errori dell'altro.\n",
    "  - Un valore **basso (es. < 0.6)** indicherebbe che i modelli hanno imparato pattern quasi completamente diversi.\n",
    "\n",
    "- **Correlazione con `TrueLabel`**: Entrambi i modelli dovrebbero mostrare una correlazione positiva con le etichette vere, indicando che le loro probabilità aumentano correttamente per la classe positiva. Il modello con la correlazione più alta rispetto a `TrueLabel` è, in generale, il più performante singolarmente.\n",
    "\n",
    "L'analisi di questa matrice ci fornisce un'indicazione quantitativa sulla diversità dei nostri modelli e sulla potenziale efficacia di combinarli."
   ]
  },
  {
   "cell_type": "code",
   "id": "c04c478f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T11:41:25.579835Z",
     "start_time": "2025-10-31T11:41:25.493097Z"
    }
   },
   "source": [
    "# Creazione DataFrame per l'analisi\n",
    "predictions_df = pd.DataFrame({\n",
    "    'TrueLabel': y_test,\n",
    "    'XGBoost_Proba': xgb_preds_proba,\n",
    "    'MLP_Proba': mlp_preds_proba\n",
    "})\n",
    "\n",
    "# Calcolo della matrice di correlazione\n",
    "correlation_matrix = predictions_df.corr()\n",
    "\n",
    "print(\"Matrice di Correlazione:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualizzazione con heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    correlation_matrix,\n",
    "    annot=True,\n",
    "    cmap='coolwarm',\n",
    "    fmt='.3f',\n",
    "    linewidths=.5\n",
    ")\n",
    "plt.title('Matrice di Correlazione tra Previsioni dei Modelli', fontsize=14, fontweight='bold')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Creazione DataFrame per l'analisi\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m predictions_df = \u001B[43mpd\u001B[49m.DataFrame({\n\u001B[32m      3\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mTrueLabel\u001B[39m\u001B[33m'\u001B[39m: y_test,\n\u001B[32m      4\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mXGBoost_Proba\u001B[39m\u001B[33m'\u001B[39m: xgb_preds_proba,\n\u001B[32m      5\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mMLP_Proba\u001B[39m\u001B[33m'\u001B[39m: mlp_preds_proba\n\u001B[32m      6\u001B[39m })\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m# Calcolo della matrice di correlazione\u001B[39;00m\n\u001B[32m      9\u001B[39m correlation_matrix = predictions_df.corr()\n",
      "\u001B[31mNameError\u001B[39m: name 'pd' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "8a47e9b5",
   "metadata": {},
   "source": [
    "## 5. Calcolo e Visualizzazione della Matrice di Correlazione\n",
    "\n",
    "Creiamo un DataFrame con le etichette vere e le probabilità previste da entrambi i modelli, quindi calcoliamo la matrice di correlazione."
   ]
  },
  {
   "cell_type": "code",
   "id": "10ac29b6",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-31T11:42:31.501889Z"
    }
   },
   "source": [
    "# Previsioni XGBoost\n",
    "print(\"Generazione previsioni XGBoost...\")\n",
    "xgb_preds_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Previsioni MLP\n",
    "print(\"Generazione previsioni MLP...\")\n",
    "\n",
    "# 1. Standardizzazione dei dati (usando lo scaler fittato sui dati di train)\n",
    "# Per farlo correttamente, carichiamo X_train solo per fittare lo scaler\n",
    "X_train_for_scaler = pd.read_csv('../data/processed_v3_balanced/X_train.csv')\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_for_scaler)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 2. Conversione a tensore\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "\n",
    "# 3. Generazione previsioni\n",
    "with torch.no_grad():\n",
    "    mlp_outputs = mlp_model(X_test_tensor)\n",
    "    mlp_preds_proba = torch.sigmoid(mlp_outputs).cpu().numpy().flatten()\n",
    "\n",
    "print(\"\\n✅ Previsioni generate per entrambi i modelli.\")\n",
    "print(f\"Esempio probabilità XGBoost: {xgb_preds_proba[:5]}\")\n",
    "print(f\"Esempio probabilità MLP:    {mlp_preds_proba[:5]}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generazione previsioni XGBoost...\n",
      "Generazione previsioni MLP...\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2c9eb7dc",
   "metadata": {},
   "source": [
    "## 4. Generazione delle Previsioni\n",
    "\n",
    "Ora generiamo le previsioni (probabilità) per entrambi i modelli sul dataset di test.\n",
    "\n",
    "- Per **XGBoost**, usiamo `predict_proba`.\n",
    "- Per **MLP**, dobbiamo prima standardizzare i dati (come nel training), convertirli in tensori e poi applicare la funzione sigmoide all'output."
   ]
  },
  {
   "cell_type": "code",
   "id": "40afc259",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T11:42:18.184880Z",
     "start_time": "2025-10-31T11:42:18.163441Z"
    }
   },
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, dropout=0.3):\n",
    "        super(MLP, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Inizializza il modello e carica i pesi\n",
    "input_dim = X_test.shape[1]\n",
    "mlp_model = MLP(input_dim, dropout=0.3).to(device)\n",
    "mlp_model.load_state_dict(torch.load('../models/mlp_baseline/model_weights.pth', map_location=device))\n",
    "mlp_model.eval()  # Imposta il modello in modalità valutazione\n",
    "\n",
    "print(\"✅ Architettura MLP definita e pesi caricati.\")\n",
    "print(mlp_model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Architettura MLP definita e pesi caricati.\n",
      "MLP(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=43, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.3, inplace=False)\n",
      "    (8): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Dropout(p=0.3, inplace=False)\n",
      "    (12): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "62a6e895",
   "metadata": {},
   "source": [
    "## 3. Definizione Architettura MLP\n",
    "\n",
    "Definiamo la classe del modello MLP. L'architettura deve essere **identica** a quella usata durante il training per poter caricare correttamente i pesi salvati."
   ]
  },
  {
   "cell_type": "code",
   "id": "9e3ea7ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T11:42:13.624892Z",
     "start_time": "2025-10-31T11:42:13.456687Z"
    }
   },
   "source": [
    "# Caricamento del dataset di test\n",
    "print(\"Caricamento dati di test...\")\n",
    "X_test = pd.read_csv('../data/processed_v3_balanced/X_test.csv')\n",
    "y_test = pd.read_csv('../data/processed_v3_balanced/y_test.csv')['BinaryIncidentGrade']\n",
    "\n",
    "# Caricamento del modello XGBoost v2\n",
    "print(\"Caricamento modello XGBoost v2...\")\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.load_model('../models/xgboost_v2/model.json')\n",
    "\n",
    "# Caricamento del modello MLP richiede prima la definizione dell'architettura\n",
    "print(\"Modello MLP pronto per essere definito e caricato.\")\n",
    "\n",
    "print(f\"\\nDimensioni X_test: {X_test.shape}\")\n",
    "print(f\"Dimensioni y_test: {y_test.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento dati di test...\n",
      "Caricamento modello XGBoost v2...\n",
      "Modello MLP pronto per essere definito e caricato.\n",
      "\n",
      "Dimensioni X_test: (149537, 43)\n",
      "Dimensioni y_test: (149537,)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "bec77aef",
   "metadata": {},
   "source": [
    "## 2. Caricamento Dati e Modelli"
   ]
  },
  {
   "cell_type": "code",
   "id": "7e2665ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T11:42:08.738475Z",
     "start_time": "2025-10-31T11:42:08.196302Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Verifica disponibilità Metal (MPS) per PyTorch\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "66f322ea",
   "metadata": {},
   "source": [
    "## 1. Setup e Import Librerie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca70d46",
   "metadata": {},
   "source": [
    "# Analisi di Correlazione tra Modelli: XGBoost vs MLP\n",
    "\n",
    "Questo notebook analizza la correlazione tra le previsioni di due dei nostri migliori modelli:\n",
    "1.  **XGBoost v2**: Il nostro modello campione basato su gradient boosting.\n",
    "2.  **MLP Standard**: Una rete neurale Multi-Layer Perceptron.\n",
    "\n",
    "L'obiettivo è capire quanto le previsioni dei due modelli siano simili o dissimili. Una bassa correlazione potrebbe indicare che i modelli catturano pattern diversi nei dati, suggerendo che un loro *ensemble* potrebbe portare a performance superiori."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
