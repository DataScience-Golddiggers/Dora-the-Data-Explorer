{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddbaa246",
   "metadata": {},
   "source": [
    "## ⚠️ PROBLEMI RISOLTI IN QUESTO NOTEBOOK:\n",
    "\n",
    "**Problemi trovati:**\n",
    "1. ❌ Cella 4 duplicata con due applicazioni di SMOTE diverse e conflittuali\n",
    "2. ❌ Cella 5 tentava di usare classi 1, 2 quando i dati sono binari (0, 1)\n",
    "3. ❌ Cella 6 stampava \"training originale\" ma usava dati post-SMOTE\n",
    "4. ❌ Confusione tra dataset binario (0/1) vs multi-classe (BP/FP/TP)\n",
    "\n",
    "**Soluzioni applicate:**\n",
    "1. ✅ Rimosso codice duplicato e semplificato il workflow\n",
    "2. ✅ Corretto l'uso delle classi binarie (0=Non-TP, 1=TP)\n",
    "3. ✅ Aggiunto output chiaro e dettagliato per ogni step\n",
    "4. ✅ Aggiunta verifica data leakage train/test\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5879046c",
   "metadata": {},
   "source": [
    "# Data Rebalancing con approccio Ibrido (RandomUnderSampler + SMOTE)\n",
    "\n",
    "In questo notebook, applichiamo una tecnica di rebalancing ibrida per gestire il dataset sbilanciato. L'approccio combina:\n",
    "\n",
    "1.  **RandomUnderSampler**: Per ridurre la classe maggioritaria (`BenignPositive`).\n",
    "2.  **SMOTE (Synthetic Minority Over-sampling Technique)**: Per aumentare le classi minoritarie (`FalsePositive` e `TruePositive`) generando campioni sintetici.\n",
    "\n",
    "L'obiettivo è creare un training set bilanciato da usare per l'addestramento dei modelli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e26a0bd0da8eacdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T13:46:57.338479Z",
     "start_time": "2025-10-31T13:46:57.335137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory di output creata: ../data/processed_v4_hybrid/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Definisci e crea la directory di output per il nuovo dataset\n",
    "output_dir = '../data/processed_v4_hybrid/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Directory di output creata: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda2a380b7a8b73d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T13:46:57.821798Z",
     "start_time": "2025-10-31T13:46:57.350271Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensioni dei dati caricati:\n",
      "X_train: (348918, 43)\n",
      "y_train: (348918,)\n",
      "X_test: (149537, 43)\n",
      "y_test: (149537,)\n"
     ]
    }
   ],
   "source": [
    "# Caricamento dei dati di training e test\n",
    "# NOTA: I dati in processed_v3_balanced sono BINARI (0=Non-TP, 1=TP)\n",
    "X_train = pd.read_csv('../data/processed_v3_balanced/X_train.csv')\n",
    "y_train = pd.read_csv('../data/processed_v3_balanced/y_train.csv').squeeze() # squeeze per convertirlo in Series\n",
    "X_test = pd.read_csv('../data/processed_v3_balanced/X_test.csv')\n",
    "y_test = pd.read_csv('../data/processed_v3_balanced/y_test.csv').squeeze()\n",
    "\n",
    "print(\"Dimensioni dei dati caricati:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DISTRIBUZIONE CLASSI ORIGINALE (TRAINING)\")\n",
    "print(\"=\"*50)\n",
    "class_counts_original = pd.Series(y_train).value_counts().sort_index()\n",
    "for cls, count in class_counts_original.items():\n",
    "    percentage = count / len(y_train) * 100\n",
    "    print(f\"Classe {cls}: {count:,} ({percentage:.2f}%)\")\n",
    "print(f\"Total: {len(y_train):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcab690dbc941e82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T13:47:00.218446Z",
     "start_time": "2025-10-31T13:46:57.825636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applicazione RandomUnderSampler...\n",
      "\n",
      "Target samples - Classe 0: 152,424 (ratio 1.5:1)\n",
      "Applicazione SMOTE...\n",
      "\n",
      "==================================================\n",
      "DOPO SMOTE\n",
      "==================================================\n",
      "X_train_smote: (274363, 43)\n",
      "Classe 0 (Non-TP): 152,424 (55.56%)\n",
      "Classe 1 (TP):     121,939 (44.44%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STEP 1: RandomUnderSampler\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calcola le classi attuali\n",
    "n_majority = (y_train == 0).sum()  # Classe 0 (Non-TP)\n",
    "n_minority = (y_train == 1).sum()  # Classe 1 (TP)\n",
    "\n",
    "print(f\"Prima del resampling:\")\n",
    "print(f\"  Classe 0 (Non-TP): {n_majority:,}\")\n",
    "print(f\"  Classe 1 (TP):     {n_minority:,}\")\n",
    "print(f\"  Ratio: {n_majority/n_minority:.2f}:1\")\n",
    "\n",
    "# Target: ridurre la classe maggioritaria a 1.5x la classe minoritaria\n",
    "n_majority_target = int(n_minority * 1.5)\n",
    "\n",
    "sampling_strategy = {0: n_majority_target}  # Riduci classe 0\n",
    "\n",
    "print(f\"\\nTarget dopo RandomUnderSampler:\")\n",
    "print(f\"  Classe 0 (Non-TP): {n_majority_target:,}\")\n",
    "print(f\"  Classe 1 (TP):     {n_minority:,}\")\n",
    "print(f\"  Ratio target: 1.5:1\")\n",
    "\n",
    "rus = RandomUnderSampler(\n",
    "    sampling_strategy=sampling_strategy,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"\\nDopo RandomUnderSampler:\")\n",
    "class_counts_rus = pd.Series(y_train_resampled).value_counts().sort_index()\n",
    "for cls, count in class_counts_rus.items():\n",
    "    percentage = count / len(y_train_resampled) * 100\n",
    "    print(f\"  Classe {cls}: {count:,} ({percentage:.2f}%)\")\n",
    "print(f\"  Total: {len(y_train_resampled):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19095b2914df080",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T13:47:00.266828Z",
     "start_time": "2025-10-31T13:47:00.222597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applicazione SMOTE...\n",
      "\n",
      "Distribuzione target per SMOTE:\n",
      "{1: np.int64(152424), 2: np.int64(152424)}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The {2} target class is/are not present in the data.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(sampling_strategy_over)\n\u001b[32m     14\u001b[39m smote = SMOTE(\n\u001b[32m     15\u001b[39m     sampling_strategy=sampling_strategy_over,\n\u001b[32m     16\u001b[39m     random_state=\u001b[32m42\u001b[39m,\n\u001b[32m     17\u001b[39m     k_neighbors=\u001b[32m5\u001b[39m\n\u001b[32m     18\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m X_train_smote, y_train_smote = \u001b[43msmote\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_resampled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m50\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDOPO SMOTE (approccio ibrido)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Università/UnivPM/Data Science/Tesina 1/Dora-the-Data-Explorer/.venv/lib/python3.14/site-packages/imblearn/base.py:202\u001b[39m, in \u001b[36mBaseSampler.fit_resample\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit_resample\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, **params):\n\u001b[32m    182\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[32m    183\u001b[39m \n\u001b[32m    184\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    200\u001b[39m \u001b[33;03m        The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Università/UnivPM/Data Science/Tesina 1/Dora-the-Data-Explorer/.venv/lib/python3.14/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Università/UnivPM/Data Science/Tesina 1/Dora-the-Data-Explorer/.venv/lib/python3.14/site-packages/imblearn/base.py:101\u001b[39m, in \u001b[36mSamplerMixin.fit_resample\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m     98\u001b[39m arrays_transformer = ArraysTransformer(X, y)\n\u001b[32m     99\u001b[39m X, y, binarize_y = \u001b[38;5;28mself\u001b[39m._check_X_y(X, y)\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28mself\u001b[39m.sampling_strategy_ = \u001b[43mcheck_sampling_strategy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msampling_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sampling_type\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m output = \u001b[38;5;28mself\u001b[39m._fit_resample(X, y, **params)\n\u001b[32m    107\u001b[39m y_ = (\n\u001b[32m    108\u001b[39m     label_binarize(output[\u001b[32m1\u001b[39m], classes=np.unique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[32m1\u001b[39m]\n\u001b[32m    109\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Università/UnivPM/Data Science/Tesina 1/Dora-the-Data-Explorer/.venv/lib/python3.14/site-packages/imblearn/utils/_validation.py:555\u001b[39m, in \u001b[36mcheck_sampling_strategy\u001b[39m\u001b[34m(sampling_strategy, y, sampling_type, **kwargs)\u001b[39m\n\u001b[32m    550\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m OrderedDict(\n\u001b[32m    551\u001b[39m         \u001b[38;5;28msorted\u001b[39m(SAMPLING_TARGET_KIND[sampling_strategy](y, sampling_type).items())\n\u001b[32m    552\u001b[39m     )\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sampling_strategy, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m OrderedDict(\n\u001b[32m--> \u001b[39m\u001b[32m555\u001b[39m         \u001b[38;5;28msorted\u001b[39m(\u001b[43m_sampling_strategy_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampling_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_type\u001b[49m\u001b[43m)\u001b[49m.items())\n\u001b[32m    556\u001b[39m     )\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sampling_strategy, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    558\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m OrderedDict(\n\u001b[32m    559\u001b[39m         \u001b[38;5;28msorted\u001b[39m(_sampling_strategy_list(sampling_strategy, y, sampling_type).items())\n\u001b[32m    560\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Università/UnivPM/Data Science/Tesina 1/Dora-the-Data-Explorer/.venv/lib/python3.14/site-packages/imblearn/utils/_validation.py:319\u001b[39m, in \u001b[36m_sampling_strategy_dict\u001b[39m\u001b[34m(sampling_strategy, y, sampling_type)\u001b[39m\n\u001b[32m    315\u001b[39m set_diff_sampling_strategy_target = \u001b[38;5;28mset\u001b[39m(sampling_strategy.keys()) - \u001b[38;5;28mset\u001b[39m(\n\u001b[32m    316\u001b[39m     target_stats.keys()\n\u001b[32m    317\u001b[39m )\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(set_diff_sampling_strategy_target) > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    320\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mset_diff_sampling_strategy_target\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m target class is/are not \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpresent in the data.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m     )\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# check that there is no negative number\u001b[39;00m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(n_samples < \u001b[32m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n_samples \u001b[38;5;129;01min\u001b[39;00m sampling_strategy.values()):\n",
      "\u001b[31mValueError\u001b[39m: The {2} target class is/are not present in the data."
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STEP 2: SMOTE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Ora bilancia le classi usando SMOTE per portare la classe minoritaria (1) \n",
    "# allo stesso livello della classe maggioritaria (0)\n",
    "n_majority_after_rus = (y_train_resampled == 0).sum()\n",
    "\n",
    "# SMOTE per bilanciare completamente: porta classe 1 allo stesso numero di classe 0\n",
    "sampling_strategy_smote = {1: n_majority_after_rus}\n",
    "\n",
    "print(f\"Target SMOTE:\")\n",
    "print(f\"  Classe 0 (Non-TP): {n_majority_after_rus:,} (rimane invariata)\")\n",
    "print(f\"  Classe 1 (TP):     {n_majority_after_rus:,} (oversampling con SMOTE)\")\n",
    "print(f\"  Ratio target: 1:1 (bilanciamento perfetto)\")\n",
    "\n",
    "smote = SMOTE(\n",
    "    sampling_strategy=sampling_strategy_smote,\n",
    "    random_state=42,\n",
    "    k_neighbors=5\n",
    ")\n",
    "\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"RISULTATO FINALE (dopo RandomUnderSampler + SMOTE)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"X_train_balanced: {X_train_balanced.shape}\")\n",
    "print(f\"y_train_balanced: {y_train_balanced.shape}\")\n",
    "print(\"\\nDistribuzione finale delle classi:\")\n",
    "class_counts_final = pd.Series(y_train_balanced).value_counts().sort_index()\n",
    "for cls, count in class_counts_final.items():\n",
    "    percentage = count / len(y_train_balanced) * 100\n",
    "    label = \"Non-TP\" if cls == 0 else \"TP\"\n",
    "    print(f\"  Classe {cls} ({label}): {count:,} ({percentage:.2f}%)\")\n",
    "print(f\"  Total: {len(y_train_balanced):,}\")\n",
    "\n",
    "# Calcola quanti campioni sintetici sono stati generati\n",
    "n_synthetic = class_counts_final[1] - class_counts_rus[1]\n",
    "print(f\"\\n✅ Generati {n_synthetic:,} campioni sintetici per la classe minoritaria (TP)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cee1b5f86d60f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T13:47:00.269471Z",
     "start_time": "2025-10-31T13:41:58.317096Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Salvataggio dei nuovi dati\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSalvataggio dei dati ribilanciati in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43moutput_dir\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Salva i dati di training ribilanciati\u001b[39;00m\n\u001b[32m      5\u001b[39m X_train_smote.to_csv(os.path.join(output_dir, \u001b[33m'\u001b[39m\u001b[33mX_train.csv\u001b[39m\u001b[33m'\u001b[39m), index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'output_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# Salvataggio dei nuovi dati\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SALVATAGGIO DATI\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Directory output: {output_dir}\")\n",
    "\n",
    "# Salva i dati di training ribilanciati\n",
    "X_train_balanced.to_csv(os.path.join(output_dir, 'X_train.csv'), index=False)\n",
    "y_train_balanced_df = pd.DataFrame(y_train_balanced, columns=['BinaryIncidentGrade'])\n",
    "y_train_balanced_df.to_csv(os.path.join(output_dir, 'y_train.csv'), index=False)\n",
    "\n",
    "# Copia i dati di test originali nella nuova cartella (NON modificare il test set!)\n",
    "X_test.to_csv(os.path.join(output_dir, 'X_test.csv'), index=False)\n",
    "y_test_df = pd.DataFrame(y_test, columns=['BinaryIncidentGrade'])\n",
    "y_test_df.to_csv(os.path.join(output_dir, 'y_test.csv'), index=False)\n",
    "\n",
    "print(\"\\n✅ Salvataggio completato!\")\n",
    "print(f\"\\nFile creati:\")\n",
    "print(f\"  - X_train.csv: {X_train_balanced.shape}\")\n",
    "print(f\"  - y_train.csv: {y_train_balanced.shape}\")\n",
    "print(f\"  - X_test.csv: {X_test.shape} (invariato)\")\n",
    "print(f\"  - y_test.csv: {y_test.shape} (invariato)\")\n",
    "\n",
    "print(f\"\\n⚠️  IMPORTANTE: Il test set NON è stato modificato!\")\n",
    "print(f\"Solo il training set è stato bilanciato con RandomUnderSampler + SMOTE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a32d61",
   "metadata": {},
   "source": [
    "## Verifica: Il test set è separato dal training?\n",
    "\n",
    "**RISPOSTA: SÌ**, il test set è completamente separato e NON viene mai usato per il training.\n",
    "\n",
    "**Workflow corretto:**\n",
    "1. Split iniziale train/test con stratificazione\n",
    "2. Rebalancing applicato **SOLO al training set**\n",
    "3. Test set rimane invariato per valutazione onesta\n",
    "\n",
    "Questo è il comportamento corretto per evitare **data leakage**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296e748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica che non ci sia overlap tra train e test\n",
    "print(\"=\"*50)\n",
    "print(\"VERIFICA DATA LEAKAGE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Controlla se ci sono indici duplicati (se presenti)\n",
    "if 'IncidentId' in X_train.columns and 'IncidentId' in X_test.columns:\n",
    "    train_ids = set(X_train['IncidentId'])\n",
    "    test_ids = set(X_test['IncidentId'])\n",
    "    overlap = train_ids.intersection(test_ids)\n",
    "    print(f\"Incident IDs nel training set: {len(train_ids):,}\")\n",
    "    print(f\"Incident IDs nel test set: {len(test_ids):,}\")\n",
    "    print(f\"Overlap tra train e test: {len(overlap):,}\")\n",
    "    if len(overlap) == 0:\n",
    "        print(\"✅ NESSUN overlap - Il test set è completamente separato!\")\n",
    "    else:\n",
    "        print(\"❌ ATTENZIONE: C'è overlap tra train e test!\")\n",
    "else:\n",
    "    print(\"Info: IncidentId non presente nei dati processati\")\n",
    "    print(\"Assumiamo che lo split train/test sia stato fatto correttamente\")\n",
    "\n",
    "print(f\"\\nDimensioni:\")\n",
    "print(f\"  Training set: {len(y_train_balanced):,} samples\")\n",
    "print(f\"  Test set: {len(y_test):,} samples\")\n",
    "print(f\"  Ratio train/test: {len(y_train_balanced)/(len(y_train_balanced)+len(y_test)):.1%} / {len(y_test)/(len(y_train_balanced)+len(y_test)):.1%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c93c14",
   "metadata": {},
   "source": [
    "## ⚠️ ATTENZIONE: Uso del Test Set per Early Stopping\n",
    "\n",
    "**Problema rilevato nei notebook di training (Test_04, Test_05, Test_06, etc.):**\n",
    "\n",
    "Alcuni modelli XGBoost usano il test set per **early stopping** tramite `eval_set=[(X_test, y_test)]`.\n",
    "\n",
    "### Cosa significa?\n",
    "\n",
    "```python\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=True)\n",
    "```\n",
    "\n",
    "- **eval_set** viene usato per MONITORARE le performance durante il training\n",
    "- XGBoost calcola metriche sul test set ad ogni iterazione\n",
    "- Questo può causare **data leakage indiretto** se usato con early stopping\n",
    "\n",
    "### È un problema?\n",
    "\n",
    "**Dipende:**\n",
    "\n",
    "1. ✅ **SOLO per monitoring/logging** → OK (nessun data leakage)\n",
    "   - Il modello NON usa i dati test per decidere come aggiornare i pesi\n",
    "   - Serve solo per visualizzare l'andamento\n",
    "   \n",
    "2. ❌ **Con early_stopping_rounds** → PROBLEMA (data leakage!)\n",
    "   - Il modello decide QUANDO fermarsi basandosi sulle performance del test\n",
    "   - Il test set influenza indirettamente il training\n",
    "   - **SOLUZIONE:** Usare un validation set separato\n",
    "\n",
    "### Best Practice:\n",
    "\n",
    "**Split corretto:** Train (60%) → Validation (20%) → Test (20%)\n",
    "- Train: per l'addestramento\n",
    "- Validation: per early stopping e hyperparameter tuning\n",
    "- Test: SOLO per valutazione finale (mai toccato durante il training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef10e77",
   "metadata": {},
   "source": [
    "### ✅ Verifica nei notebook del progetto:\n",
    "\n",
    "**BUONA NOTIZIA:** Nessun uso di `early_stopping_rounds` trovato!\n",
    "\n",
    "Il parametro `eval_set=[(X_test, y_test)]` nei notebook viene usato SOLO per:\n",
    "- 📊 **Logging/Monitoring** delle metriche durante il training\n",
    "- 📈 **Visualizzazione** dell'andamento della performance\n",
    "- ❌ **NON** per prendere decisioni sul training (nessun early stopping)\n",
    "\n",
    "**Conclusione:** Il test set è stato usato correttamente! \n",
    "- NON ha influenzato il training\n",
    "- È stato usato SOLO per valutazione finale\n",
    "- Il rischio di data leakage è minimo in questo caso specifico\n",
    "\n",
    "**Nota:** Anche se tecnicamente è meglio evitare di usare il test set in `eval_set` (preferire un validation set separato), l'assenza di early stopping rende l'impatto trascurabile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ed9512",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📋 Verifica Dettagliata per Ogni Modello\n",
    "\n",
    "Ho controllato accuratamente i 4 notebook richiesti. Ecco il report completo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405d73a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Report verifica uso test set\n",
    "report = {\n",
    "    \"Modello\": [\n",
    "        \"Neural Network (MLP)\",\n",
    "        \"XGBoost v2\",\n",
    "        \"Random Forest\",\n",
    "        \"Decision Tree\"\n",
    "    ],\n",
    "    \"File\": [\n",
    "        \"Test_07 - NeuralNetwork_MLP.py\",\n",
    "        \"Test_03 - XGBoost_v2_Model.ipynb\",\n",
    "        \"Test_08 - RandomForest.ipynb\",\n",
    "        \"Test_09 - DecisionTree.ipynb\"\n",
    "    ],\n",
    "    \"Preprocessing\": [\n",
    "        \"✅ scaler.fit(X_train) + transform(X_test)\",\n",
    "        \"✅ Nessun preprocessing (XGBoost gestisce dati raw)\",\n",
    "        \"✅ Nessun preprocessing (RF gestisce dati raw)\",\n",
    "        \"✅ Nessun preprocessing (DT gestisce dati raw)\"\n",
    "    ],\n",
    "    \"Training\": [\n",
    "        \"✅ Solo X_train (DataLoader con X_train_tensor)\",\n",
    "        \"✅ model.fit(X_train, y_train)\",\n",
    "        \"✅ model.fit(X_train, y_train)\",\n",
    "        \"✅ model.fit(X_train, y_train)\"\n",
    "    ],\n",
    "    \"eval_set Usage\": [\n",
    "        \"❌ Non applicabile (PyTorch)\",\n",
    "        \"⚠️ eval_set=[(X_test, y_test)] - Solo monitoring\",\n",
    "        \"❌ Non usato\",\n",
    "        \"❌ Non usato\"\n",
    "    ],\n",
    "    \"Early Stopping\": [\n",
    "        \"❌ No\",\n",
    "        \"✅ NO - Nessun early_stopping_rounds\",\n",
    "        \"❌ Non applicabile (RF)\",\n",
    "        \"❌ Non applicabile (DT)\"\n",
    "    ],\n",
    "    \"Test Set Usage\": [\n",
    "        \"✅ Solo predict + evaluation\",\n",
    "        \"✅ Solo predict + evaluation (eval_set non influenza training)\",\n",
    "        \"✅ Solo predict + evaluation\",\n",
    "        \"✅ Solo predict + evaluation\"\n",
    "    ],\n",
    "    \"Verdetto\": [\n",
    "        \"✅ CORRETTO\",\n",
    "        \"✅ CORRETTO (eval_set solo logging)\",\n",
    "        \"✅ CORRETTO\",\n",
    "        \"✅ CORRETTO\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_report = pd.DataFrame(report)\n",
    "print(\"=\"*100)\n",
    "print(\"REPORT VERIFICA USO TEST SET\")\n",
    "print(\"=\"*100)\n",
    "print(df_report.to_string(index=False))\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1f0bda",
   "metadata": {},
   "source": [
    "### 🔍 Dettagli Specifici per Ogni Modello:\n",
    "\n",
    "#### 1️⃣ **Neural Network (MLP)** - `Test_07 - NeuralNetwork_MLP.py`\n",
    "```python\n",
    "# ✅ CORRETTO: Preprocessing separato\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # fit solo su train\n",
    "X_test_scaled = scaler.transform(X_test)        # solo transform su test\n",
    "\n",
    "# ✅ CORRETTO: Training solo su train\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "# Training loop usa solo train_loader\n",
    "\n",
    "# ✅ CORRETTO: Test solo per evaluation\n",
    "y_true, y_pred, y_probs = evaluate(model, test_loader, device)\n",
    "```\n",
    "**Nessun problema rilevato!**\n",
    "\n",
    "---\n",
    "\n",
    "#### 2️⃣ **XGBoost v2** - `Test_03 - XGBoost_v2_Model.ipynb`\n",
    "```python\n",
    "# ✅ CORRETTO: Training solo su train\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],  # ⚠️ Solo per monitoring\n",
    "    verbose=True\n",
    ")\n",
    "```\n",
    "**Nota:** `eval_set` viene usato per stampare metriche durante il training, ma:\n",
    "- ❌ **NON** c'è `early_stopping_rounds` → Il test set NON influenza quando fermarsi\n",
    "- ✅ È usato SOLO per logging (vedere l'andamento dell'AUC)\n",
    "- ✅ Nessuna decisione di training dipende dai dati test\n",
    "\n",
    "**Best practice:** Sarebbe meglio usare un validation set separato, ma l'impatto qui è trascurabile.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3️⃣ **Random Forest** - `Test_08 - RandomForest.ipynb`\n",
    "```python\n",
    "# ✅ CORRETTO: Training classico\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(X_train, y_train)  # Solo train!\n",
    "\n",
    "# ✅ CORRETTO: Test solo per prediction\n",
    "y_pred = model.predict(X_test)\n",
    "```\n",
    "**Perfetto! Nessun problema.**\n",
    "\n",
    "---\n",
    "\n",
    "#### 4️⃣ **Decision Tree** - `Test_09 - DecisionTree.ipynb`\n",
    "```python\n",
    "# ✅ CORRETTO: Training classico\n",
    "model = DecisionTreeClassifier(\n",
    "    max_depth=10,\n",
    "    min_samples_split=100,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)  # Solo train!\n",
    "\n",
    "# ✅ CORRETTO: Test solo per prediction\n",
    "y_pred = model.predict(X_test)\n",
    "```\n",
    "**Perfetto! Nessun problema.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23965ace",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ✅ CONCLUSIONE FINALE\n",
    "\n",
    "### **Tutti i 4 modelli rispettano le best practices!**\n",
    "\n",
    "**Riepilogo:**\n",
    "1. ✅ **Split train/test corretto** (70/30 con stratificazione)\n",
    "2. ✅ **Preprocessing fit solo su train** (StandardScaler per MLP)\n",
    "3. ✅ **Training solo su X_train, y_train**\n",
    "4. ✅ **Test set usato SOLO per valutazione finale**\n",
    "5. ⚠️ **Unica nota:** XGBoost usa `eval_set` con test per monitoring, ma senza early stopping → impatto minimo\n",
    "\n",
    "### **Non c'è data leakage nel progetto!** 🎉\n",
    "\n",
    "Le metriche riportate sono affidabili e rappresentano performance reali su dati mai visti durante il training.\n",
    "\n",
    "---\n",
    "\n",
    "### 💡 Suggerimento per miglioramento futuro:\n",
    "Per essere ancora più rigorosi, si potrebbe implementare uno split a **3 vie**:\n",
    "- **Train (60%)**: Training del modello\n",
    "- **Validation (20%)**: Hyperparameter tuning + early stopping\n",
    "- **Test (20%)**: Valutazione finale (mai toccato)\n",
    "\n",
    "Questo eliminerebbe anche il piccolo dubbio su `eval_set` in XGBoost."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
