# Dora the Data Explorer - GUIDE Dataset Pipeline

Pipeline completa per classificazione di incidenti di cybersecurity usando il dataset GUIDE (Microsoft).

## ğŸš€ Quick Start

```bash
# 1. Installa dipendenze
pip install -r requirements.txt

# 2. Preprocessing
cd src/preprocessing
python run_preprocessing.py \
    --train_file ../../data/GUIDE_Train.csv \
    --test_file ../../data/GUIDE_Test.csv \
    --output_dir ../../data/processed_v3_balanced \
    --balance_strategy augment \
    --save_pipeline

# 3. Training (esempio con XGBoost)
cd ../training
python train_xgboost.py \
    --data_dir ../../data/processed_v3_balanced \
    --model_dir ../../models/xgboost_v2

# 4. Inferenza
cd ../inference
python inference_pipeline.py \
    --input_file ../../data/GUIDE_Test.csv \
    --output_file ../../predictions.csv \
    --model_dir ../../models/xgboost_v2 \
    --model_type xgboost
```

## ğŸ“ Struttura del Progetto

```
Dora-the-Data-Explorer/
â”œâ”€â”€ data/                           # Dataset
â”‚   â”œâ”€â”€ GUIDE_Train.csv            # Training raw
â”‚   â”œâ”€â”€ GUIDE_Test.csv             # Test raw
â”‚   â”œâ”€â”€ processed_v3/              # Dati processati (no balancing)
â”‚   â””â”€â”€ processed_v3_balanced/     # Dati processati + bilanciati
â”œâ”€â”€ src/                            # Codice sorgente
â”‚   â”œâ”€â”€ preprocessing/             # Feature engineering e balancing
â”‚   â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”‚   â”œâ”€â”€ data_rebalancing.py
â”‚   â”‚   â””â”€â”€ run_preprocessing.py
â”‚   â”œâ”€â”€ training/                  # Training modelli
â”‚   â”‚   â”œâ”€â”€ train_xgboost.py
â”‚   â”‚   â”œâ”€â”€ train_random_forest.py
â”‚   â”‚   â””â”€â”€ train_mlp.py
â”‚   â””â”€â”€ inference/                 # Inferenza
â”‚       â””â”€â”€ inference_pipeline.py
â”œâ”€â”€ models/                         # Modelli trainati
â”‚   â”œâ”€â”€ preprocessing_pipeline.pkl # Pipeline per inferenza
â”‚   â”œâ”€â”€ xgboost_v2/
â”‚   â”œâ”€â”€ random_forest_v2/
â”‚   â””â”€â”€ mlp_baseline/
â”œâ”€â”€ notebook/                       # Jupyter notebooks (sviluppo)
â”œâ”€â”€ docs/                          # Documentazione
â”‚   â”œâ”€â”€ PIPELINE_USAGE.md         # Documentazione dettagliata
â”‚   â””â”€â”€ QUICK_START.md
â”œâ”€â”€ examples/                      # Esempi di utilizzo
â”‚   â””â”€â”€ complete_pipeline_example.py
â””â”€â”€ requirements.txt               # Dipendenze Python
```

## ğŸ”§ Componenti Principali

### 1. Preprocessing (`src/preprocessing/`)

**Feature Engineering Pipeline:**
- Target binario (TruePositive vs Non-TruePositive)
- SmoothedRisk con Bayesian smoothing
- Features temporali (hour, day, weekend, duration)
- GeoLoc_freq (frequenza location geografica)
- Frequency encoding per colonne ad alta cardinalitÃ 
- One-hot encoding selettivo (SuspicionLevel, EvidenceRole)
- MITRE ATT&CK top 30 techniques
- Aggregazione Evidence â†’ Incident level

**Data Rebalancing:**
- Minority class augmentation dal test set
- Undersampling della classe maggioritaria
- Split stratificato train/test

### 2. Training (`src/training/`)

**Modelli implementati:**
- **XGBoost**: Gradient boosting con `scale_pos_weight` per class imbalance
- **Random Forest**: Ensemble di decision trees con `class_weight='balanced'`
- **MLP (Neural Network)**: Multi-layer perceptron con dropout e batch normalization

Tutti i modelli salvano:
- Modello trainato (`.pkl`, `.pth`, `.json`)
- Feature importance (XGBoost, Random Forest)
- Metriche complete (`metrics.json`)
- Scaler per normalizzazione (MLP)

### 3. Inference (`src/inference/`)

**FunzionalitÃ :**
- Inferenza singola o batch
- Confronto tra piÃ¹ modelli
- Predizioni con metadata (probabilitÃ , IncidentId)
- Applicazione automatica delle trasformazioni del training

## ğŸ“Š Features (43 totali)

### Structural
- `NumAlerts`: Numero alert per incident
- `NumEvidences`: Numero evidence per incident

### Temporal
- `Hour_First`, `Hour_Last`, `Hour_Avg`
- `month`, `weekday`, `IsWeekend`
- `Duration_seconds`

### Risk
- `SmoothedRisk_avg`: Bayesian smoothing per AlertTitle
- `GeoLoc_freq_avg`: Frequenza location

### Frequency Encoded (9 features)
- `ThreatFamily_freq`, `EntityType_freq`, `Category_freq`, etc.

### One-Hot Encoded
- `SuspicionLevel_*`: ~5 features
- `EvidenceRole_*`: ~3 features

### MITRE ATT&CK
- Top 30 tecniche piÃ¹ frequenti (e.g., `T1078`, `T1566`)

## ğŸ“ˆ Metriche di Valutazione

**Metrica principale:** ROC AUC (Area Under ROC Curve) â­

**Altre metriche:**
- Accuracy
- Precision, Recall, F1-Score (per entrambe le classi)
- Confusion Matrix
- Cross-validation scores (XGBoost)

## ğŸ¯ Best Practices

### Preprocessing
âœ… Usa `fit_transform()` solo sul training set  
âœ… Usa `transform()` per test/inference  
âœ… Salva sempre la pipeline per inferenza  
âœ… SmoothedRisk usa statistiche del training (no data leakage)

### Training
âœ… XGBoost: `scale_pos_weight` per dataset non bilanciati  
âœ… Random Forest: `class_weight='balanced'` per imbalance  
âœ… MLP: **Richiede StandardScaler** (applicato automaticamente)  
âœ… Cross-validation con `StratifiedKFold`

### Inferenza
âœ… Pipeline di preprocessing **DEVE** essere salvata  
âœ… Per MLP, `scaler.pkl` Ã¨ necessario  
âœ… Le trasformazioni sono identiche al training  
âœ… Usa batch inference per file grandi

## ğŸ“– Documentazione

- **Documentazione completa**: [`docs/PIPELINE_USAGE.md`](docs/PIPELINE_USAGE.md)
- **Quick start**: [`docs/QUICK_START.md`](docs/QUICK_START.md)
- **Esempio completo**: [`examples/complete_pipeline_example.py`](examples/complete_pipeline_example.py)

## ğŸ”¬ Notebook di Sviluppo

I notebook originali da cui Ã¨ stata estratta la pipeline:
- `Test_03 - FeatureEngineering_v3.ipynb`: Feature engineering
- `Test_11 - DataRebalancing.ipynb`: Data augmentation
- `Test_03 - XGBoost_v2_Model.ipynb`: XGBoost training
- `Test_08 - RandomForest.ipynb`: Random Forest training
- `Test_07 - NeuralNetwork_MLP.ipynb`: MLP training

## ğŸ› ï¸ Requisiti

- Python 3.8+
- pandas, numpy, scikit-learn
- xgboost
- PyTorch (per MLP)
- matplotlib, seaborn (visualizzazioni)

Vedi [`requirements.txt`](requirements.txt) per la lista completa.

## ğŸ¤ Contributi

Progetto sviluppato da **DataScience-Golddiggers** per il corso di Data Science, UnivPM.

## ğŸ“ License

Vedi [`LICENSE`](LICENSE) file.

## ğŸ“ References

- **Dataset**: GUIDE (Guided Response Dataset) - Microsoft Security AI Research
- **MITRE ATT&CK**: https://attack.mitre.org/
- **Bayesian Smoothing**: Wilson score interval per binary data
